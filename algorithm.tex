\section{Ensemble Learning Algorithm}
%
The main idea of this paper is shown in
algorithm~\ref{alg:compose_model}. This is a high-level description
and the algorithm uses a diagnostic engine similar to the one
described by \cite{feldman13genius}.
%
\begin{algorithm}[htb]
\begin{footnotesize}
%
\caption{\textsc{ComposeModel}($T, \mathcal{C}, \mathcal{A}$)}
\label{alg:compose_model}
%
\KwIn{$T$, model topology}
\KwIn{$\mathcal{C}$, component library}
\KwIn{$\mathcal{A}$, set of test scenarios}
\KwResult{\sd, model}
%
\SetKwInput{KwLocals}{Local variables}
\SetKwInput{KwLocal}{Local variable}
\KwLocals{$\sd^\star$, $\sd^\prime$, models, initially $\emptyset$}
\KwLocal{$\alpha$, test scenario}
\KwLocal{$\omega$, diagnosis}
\KwLocal{$m$, diagnosis score}
\KwLocal{$m_{\min}$, optimal diagnosis score, initially $\infty$}
%
\vspace{0.075in}
%
\Repeat
{
$\textsc{Terminate?($\sd^\star, \sd^\prime, m$)}$
}
{
    $\sd^\star \gets \textsc{NextModelComposition}(T, \mathcal{C}, \sd^\prime)$\label{alg:next_model_composition}\\
    $\sd^\prime \gets \sd^\star$\\
    $m \gets 0$\\
    \ForEach{$\alpha \in \mathcal{A}$}
    {
        $\omega \gets \textsc{Diagnose}(\sd^\star, \alpha)$\\
        $m \gets m + \textsc{Evaluate}(\alpha, \omega)$\label{alg:evaluate}\\
    }
    \If{$m < m_{\min}$\label{alg:accept_start}}
    {
        $m_{\min} \gets m$\\
        $\sd \gets \sd^\star$\label{alg:accept_end}\\
    }
}
\textbf{return} $\sd$
%
\end{footnotesize}
\end{algorithm}
%
\par
%
Algorithm~\ref{alg:compose_model} is presented as
non-deterministic. The non-determinism is in the auxiliary function
\textsc{NextModelComposition}
(line~\ref{alg:next_model_composition}). This function takes a model
topology and a component library as inputs and returns a composed
model. Each component has multiple representations in the component
library (e.g., qualitative, linear, non-linear). The total number of
component combinations is, of course, $n^{|\comps|}$, where $n$ is the
number of representations. Fortunately, there is no need to perform a
complete-search over the space of all possible model compositions. A
greedy-search strategy achieves satisfactory performance in most
practical cases.
\par
A configuration of algorithm~\ref{alg:compose_model} that determines
many of the diagnostic performances is the order in which
health-assignments are generated. This is implemented in the
\textsc{NextModelComposition} function. The
\textsc{NextModelComposition} subroutine also determines when to stop
the search and should be properly parametrized depending on the model
and the user requirements. In our implementation we provide the
following model-composition search policies:
%
\begin{description}
%
\item[Breadth-First Search (BFS):]
{
%
This search policy starts with all components having the same model
types (for example non-linear), then considers all models with a
single component type change. After all single component type changes
are exhausted, the algorithm continues with pairs of components,
triples, etc.
%
}
\item[Depth-First Search (DFS):]
{
%
The algorithm starts by changing the type of the first component, then
the second, etc., until all component types are changed. At this
point, algorithm~\ref{alg:compose_model} backtracks one step,
generates a sibling assignment and continues traversing down and
backtracking in the same manner until no more backtracking is
possible.
%
}
\item[Forward Greedy Stochastic Search (FGSS):]
{
%
This is a randomized search policy. In this mode, the algorithm starts
by changing the type of one of the components. If the change improves
the metric in line~\ref{alg:evaluate} of
algorithm~\ref{alg:compose_model}, then the change is accepted (see
lines~\ref{alg:accept_start}--\ref{alg:accept_end} of
algorithm~\ref{alg:compose_model}). This is our preferred search
policy as typically the evaluation metric improves monotonically when
changing the component types one by one.
%
}
\item[Backwards Greedy Stochastic Search (BGSS):]
{
%
In this mode, the search start from all component types changed from
their defaults. The type of a random component is then flipped and the
flip is retained iff the flip leads to a decrease in total metric
evaluation score. The order of component is arbitrary. As the whole
search process is stochastic, it needs to be run multiple iterations
in order to achieve the desired completeness.
%
}
%
\end{description}
